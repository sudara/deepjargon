## [Backpropagation](#backpropagation)
*Backward propagation of errors | Backprop*

A part of the [Gradient Descent](#gradient-descent) algorithm.

After a [training example](#training-example) goes through the network, we calculate the amount of error that each [neuron](#neuron) contributed and update their weights.
