## [Backpropagation](#backpropagation)
*Backward propagation of errors | Backprop | Backwards pass*

A part of the [Gradient Descent](#gradient-descent) algorithm.

After a [training example](#training-example) (or a [batch](#batch)) goes through the network, we calculate the amount of error that each [neuron](#neuron) contributed and update their weights.
