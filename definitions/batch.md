## [Batch Size](#batch-size)

The number of [training examples](#training-example) sent to the network in one go.

The more data you try and process at once, the more computing power it needs. Batches basically just spread learning into smaller more manageable datasets. A batch is like a single day at school for the machine.

Batches make up an [epoch](#epoch).