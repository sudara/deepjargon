## [Batch](#batch)

The number of [training examples](#training-example) used to train an [artificial neural network](#artificial-neural-network) in one go.

Not to be confused with [epoch](#epoch). 

The more data you try and process at once, the more computing power it needs. Batches basically just spread learning into smaller more manageable datasets. A batch is like a single day at school for the machine. 