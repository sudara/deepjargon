## [ReLU](#relu)
*Rectified Linear Unit*

If a value is negative, use 0. Otherwise use that value.

Popular [Activation Function](#activation-function) for [hidden layers](#hidden-layers).

$$
{\displaystyle f(x)={\begin{cases}0&{\text{for }}x<0\\x&{\text{for }}x\geq 0\end{cases}}}
$$
