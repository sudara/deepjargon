## [Logits](#logits)

In the [Tensorflow](#tensorflow) world, this (confusingly) means "input going into a [softmax](#softmax) layer"

In The Mathâ„¢, it's the name of a function that performs the inverse of [softmax](#softmax), taking a probability `[0, 1]` and outputting a number `[-inf, +inf]`